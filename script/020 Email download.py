# -*- coding: utf-8 -*-
"""
020 Email download.py
åŠŸèƒ½ï¼š
1) è¯»å– .env ä¸­ QQ é‚®ç®± IMAP å‡­æ®ï¼Œç™»å½•å¹¶æŠ“å–æœ€è¿‘ N å°é‚®ä»¶ã€‚
2) ä»¥é…ç½®çš„å…³é”®è¯ç­›é€‰ä¸¤ç±»é‚®ä»¶ï¼š
   - KEYWORDS["waiting"]      â†’ â€œç­‰å¾…æ‚¨æŸ¥çœ‹â€
   - KEYWORDS["heyu_da"]      â†’ â€œåˆè‚¥å¸‚å’Œè£•è¾¾â€
   å„è‡ªé€‰å–ã€æœ€æ–°ã€‘ä¸€å°ã€‚
3) æå–é€‰ä¸­é‚®ä»¶çš„ HTML æ­£æ–‡ï¼ˆç”¨äºåç»­è§£æè¡¨æ ¼ï¼‰ï¼Œå¹¶ï¼š
   - è‹¥å‘½ä¸­ heyu_da ç±»ï¼Œä¸‹è½½å…¶é™„ä»¶åˆ°ä¿å­˜ç›®å½•ï¼ˆæ–‡ä»¶åè¿½åŠ æ—¶é—´æˆ³ï¼Œä¿ç•™åŸæ‰©å±•åï¼‰ã€‚
4) å°†â€œé€‰ä¸­çš„ subject + æ”¶åˆ°æ—¶é—´ï¼ˆISO8601ï¼‰â€å†™å…¥ä¿å­˜ç›®å½•ä¸‹çš„ mail_meta.jsonï¼Œä¾›åç»­è„šæœ¬è¯»å–ã€‚
5) è§£æ HTML ä¸­é¦–ä¸ªåˆç†è¡¨æ ¼å¹¶å¯¼å‡º Excelï¼ˆç¬¬ä¸€é¡µï¼‰ã€‚
ä½¿ç”¨ï¼š
- å¯ä¼ å…¥ä¿å­˜ç›®å½•ä½œä¸ºç¬¬1ä¸ªå‘½ä»¤è¡Œå‚æ•°ï¼›ä¸ä¼ åˆ™ä½¿ç”¨å¹³å°é»˜è®¤ç›®å½•ï¼ˆWindows: ./dataï¼›å…¶ä»–: ~/dataï¼‰ã€‚
"""

import os
import sys
import re
import time
import platform
import json
import email
import imaplib
from email.header import decode_header
from email.utils import parsedate_tz, mktime_tz
from datetime import datetime

import pandas as pd
import openpyxl
from bs4 import BeautifulSoup
from openpyxl.styles import Alignment
from dotenv import load_dotenv

# ================================
# ğŸ“‚ è·¯å¾„é…ç½®ï¼ˆæ”¯æŒä¸»ç¨‹åºä¼ å‚ï¼‰
# ================================
if platform.system() == "Windows":
    default_save_path = os.path.join(os.getcwd(), "data")  # Windows: ç›¸å¯¹è·¯å¾„ ./data
else:
    default_save_path = os.path.expanduser("~/data")       # Linux/macOS: å®¶ç›®å½• ~/data

excel_save_path = sys.argv[1] if len(sys.argv) >= 2 else default_save_path
os.makedirs(excel_save_path, exist_ok=True)
print(f"ğŸ“‚ ä¿å­˜è·¯å¾„: {os.path.abspath(excel_save_path)}")

# ================================
# ğŸ”§ å…³é”®è¯/é‚®ç®±é…ç½®ï¼ˆé›†ä¸­ç®¡ç†ï¼‰
# ================================
KEYWORDS = {
    "waiting": "ç­‰å¾…æ‚¨æŸ¥çœ‹",
    "heyu_da": "åˆè‚¥å¸‚å’Œè£•è¾¾",
}
MAILBOX = os.getenv("IMAP_MAILBOX", "INBOX")          # QQ/å¤šæ•° IMAP å…¼å®¹ "INBOX"
RECENT_LIMIT = int(os.getenv("RECENT_LIMIT", "15"))  # æœ€è¿‘æŠ“å–é‚®ä»¶æ•°é‡ä¸Šé™
META_FILENAME = "mail_meta.json"                      # å…ƒæ•°æ®æ–‡ä»¶åï¼ˆå†™å…¥ excel_save_pathï¼‰

# ================================
# ğŸ“§ é‚®ç®±å‡­æ®ï¼ˆ.envï¼‰
# ================================
load_dotenv()  # å¯æ”¹ä¸º load_dotenv(dotenv_path="...") å®šç‚¹åŠ è½½

email_user = os.getenv("EMAIL_ADDRESS_QQ")
# å…¼å®¹æ—§å†™æ³• EMAIL_PASSWOR_QQï¼ˆå°‘äº†Dï¼‰
email_password = os.getenv("EMAIL_PASSWORD_QQ") or os.getenv("EMAIL_PASSWOR_QQ")
email_server = os.getenv("IMAP_SERVER", "imap.qq.com")

if not email_user or not email_password:
    raise ValueError("âŒ ç¯å¢ƒå˜é‡æœªæ­£ç¡®é…ç½®ï¼ˆEMAIL_ADDRESS_QQ / EMAIL_PASSWORD_QQï¼‰ï¼")

print("ğŸ“¬ æ­£åœ¨ä½¿ç”¨é‚®ç®±:", email_user)

# ================================
# ğŸ”‘ æ ‡é¢˜è§£ç ä¸æ¸…ç†
# ================================
def decode_str(s: str) -> str:
    if not s:
        return ""
    value, charset = decode_header(s)[0]
    if charset:
        value = value.decode(charset)
    elif isinstance(value, bytes):
        value = value.decode("utf-8", errors="ignore")
    return value

def clean_subject(subject: str) -> str:
    cleaned_subject = re.sub(r'\[([^\[\]]+)\]', r'\1', subject or "")
    cleaned_subject = re.sub(r'ã€([^ã€ã€‘]+)ã€‘', r'\1', cleaned_subject)
    return cleaned_subject.strip()

# ================================
# ğŸ“¨ æŠ“å–é‚®ä»¶å¹¶è¾“å‡º HTML/å…ƒæ•°æ®/é™„ä»¶
# ================================
def fetch_html_from_emails(server: str, user: str, password: str, save_dir: str) -> str | None:
    mail = None
    html_content = None

    # é¢„ç½®å…ƒæ•°æ®ï¼ˆä¸¤ç±»æœ€æ–°é‚®ä»¶ï¼‰
    meta = {
        "selected_heyu_da_subject": None,
        "selected_heyu_da_received_at": None,
        "selected_waiting_subject": None,
        "selected_waiting_received_at": None,
    }

    try:
        print("ğŸ”— æ­£åœ¨è¿æ¥é‚®ç®±...")
        mail = imaplib.IMAP4_SSL(server)
        mail.login(user, password)

        # é€‰æ‹©é‚®ç®±ç›®å½•
        status, _ = mail.select(MAILBOX)
        if status != "OK":
            print(f"âš ï¸ æ— æ³•é€‰æ‹©é‚®ç®±ç›®å½• {MAILBOX}ï¼Œå°è¯•ä½¿ç”¨ INBOX")
            mail.select("INBOX")

        print(f"ğŸ” æ­£åœ¨æ£€ç´¢æœ€è¿‘ {RECENT_LIMIT} å°é‚®ä»¶...")
        status, messages = mail.search(None, "ALL")
        if status != "OK":
            print("æœªæ‰¾åˆ°é‚®ä»¶")
            return None

        mail_ids = messages[0].split()
        if not mail_ids:
            print("é‚®ç®±ä¸ºç©ºã€‚")
            return None

        recent_mail_ids = mail_ids[-RECENT_LIMIT:]
        print(f"ğŸ“¨ å…± {len(mail_ids)} å°ï¼Œå¤„ç†æœ€è¿‘ {len(recent_mail_ids)} å°ã€‚")

        inventory_query_emails = []

        # éå†æœ€è¿‘çš„ N å°é‚®ä»¶
        for i, mail_id in enumerate(recent_mail_ids, start=1):
            status, msg_data = mail.fetch(mail_id, "(RFC822)")
            if status != "OK" or not msg_data or not msg_data[0]:
                print(f"âš ï¸ ç¬¬ {i} å°æŠ“å–å¤±è´¥")
                continue

            raw_email = msg_data[0][1]
            msg = email.message_from_bytes(raw_email)

            subject = decode_str(msg.get("Subject"))
            from_ = decode_str(msg.get("From"))
            date_raw = decode_str(msg.get("Date"))

            # è½¬æ¢ä¸º datetimeï¼Œå¤±è´¥åˆ™å…œåº•ä¸º 1970-01-01
            mail_date = parsedate_tz(date_raw)
            if mail_date:
                mail_datetime = datetime.fromtimestamp(mktime_tz(mail_date))
            else:
                mail_datetime = datetime(1970, 1, 1)

            cleaned_subject = clean_subject(subject)

            print(f"  Â· ç¬¬ {i} å° | åŸ: {subject} | æ¸…ç†: {cleaned_subject} | å‘ä»¶äºº: {from_} | æ”¶åˆ°: {mail_datetime}")

            # ä»…æ”¶é›†æ ‡é¢˜å‘½ä¸­ä¸¤ç±»å…³é”®è¯çš„é‚®ä»¶
            if (KEYWORDS["waiting"] in cleaned_subject) or (KEYWORDS["heyu_da"] in cleaned_subject):
                inventory_query_emails.append({
                    "mail_id": mail_id,
                    "subject": subject,
                    "cleaned_subject": cleaned_subject,
                    "date": mail_datetime,
                    "msg": msg
                })

        # æ‰“å°ç­›é€‰åˆ—è¡¨
        if inventory_query_emails:
            print("\nâœ… å‘½ä¸­å…³é”®è¯çš„é‚®ä»¶ï¼š")
            for item in inventory_query_emails:
                print(f"  - {item['cleaned_subject']} | {item['date']}")
        else:
            print("\nâ„¹ï¸ æœªå‘½ä¸­ä»»ä½•å…³é”®è¯é‚®ä»¶ã€‚")

        # é€‰å‡ºâ€œåˆè‚¥å¸‚å’Œè£•è¾¾â€æœ€æ–°ä¸€å° â†’ æå– HTML + ä¸‹è½½é™„ä»¶
        selected_heyu = _pick_latest(inventory_query_emails, KEYWORDS["heyu_da"])
        if selected_heyu:
            html_content = extract_html_from_msg(selected_heyu["msg"]) or html_content
            print(f"\nğŸ“Œ é€‰ä¸­(åˆè‚¥å¸‚å’Œè£•è¾¾): {selected_heyu['cleaned_subject']} | {selected_heyu['date']}")
            meta["selected_heyu_da_subject"] = selected_heyu["cleaned_subject"]
            meta["selected_heyu_da_received_at"] = selected_heyu["date"].isoformat() if selected_heyu["date"] else None
            # ä¸‹è½½é™„ä»¶
            download_attachments(selected_heyu["msg"], save_dir)

        # é€‰å‡ºâ€œç­‰å¾…æ‚¨æŸ¥çœ‹â€æœ€æ–°ä¸€å° â†’ æå– HTML
        selected_waiting = _pick_latest(inventory_query_emails, KEYWORDS["waiting"])
        if selected_waiting:
            html_content = extract_html_from_msg(selected_waiting["msg"]) or html_content
            print(f"\nğŸ“Œ é€‰ä¸­(ç­‰å¾…æ‚¨æŸ¥çœ‹): {selected_waiting['cleaned_subject']} | {selected_waiting['date']}")
            meta["selected_waiting_subject"] = selected_waiting["cleaned_subject"]
            meta["selected_waiting_received_at"] = selected_waiting["date"].isoformat() if selected_waiting["date"] else None

        # å†™å‡ºå…ƒæ•°æ®
        _write_meta(meta, os.path.join(save_dir, META_FILENAME))

        if html_content:
            print("âœ… å·²è·å–é€‰å®šé‚®ä»¶çš„ HTML æ­£æ–‡ã€‚")
        else:
            print("â„¹ï¸ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ HTML æ­£æ–‡ã€‚")

        return html_content

    except imaplib.IMAP4.error as e:
        print(f"IMAP é”™è¯¯: {e}")
        return None
    except Exception as e:
        print(f"è·å–é‚®ä»¶å¤±è´¥: {e}")
        return None
    finally:
        try:
            if mail is not None:
                mail.logout()
        except Exception:
            pass

def _pick_latest(candidates: list[dict], keyword: str) -> dict | None:
    """åœ¨ candidates ä¸­é€‰å‡º cleaned_subject å« keyword çš„ã€æœ€æ–°ã€‘ä¸€å°ã€‚"""
    selected = None
    for item in candidates:
        if keyword in item["cleaned_subject"]:
            if (selected is None) or (item["date"] > selected["date"]):
                selected = item
    return selected

# ================================
# ğŸ§© ä»é‚®ä»¶ä¸­æå– HTML æ­£æ–‡
# ================================
def extract_html_from_msg(msg) -> str | None:
    html_content = None
    if msg.is_multipart():
        for part in msg.walk():
            content_type = part.get_content_type()
            content_disposition = str(part.get("Content-Disposition") or "")
            if content_type == "text/html" and "attachment" not in content_disposition:
                charset = part.get_content_charset() or part.get_charset() or "utf-8"
                try:
                    html_content = part.get_payload(decode=True).decode(charset, errors="ignore")
                except Exception:
                    html_content = part.get_payload(decode=True).decode("utf-8", errors="ignore")
                break
    else:
        if msg.get_content_type() == "text/html":
            charset = msg.get_content_charset() or msg.get_charset() or "utf-8"
            try:
                html_content = msg.get_payload(decode=True).decode(charset, errors="ignore")
            except Exception:
                html_content = msg.get_payload(decode=True).decode("utf-8", errors="ignore")
    return html_content

# ================================
# ğŸ“ ä¸‹è½½é™„ä»¶ï¼ˆè¿½åŠ æ—¶é—´æˆ³ï¼Œä¿ç•™æ‰©å±•åï¼‰
# ================================
def download_attachments(msg, download_folder: str) -> None:
    """ä¸‹è½½é‚®ä»¶é™„ä»¶ï¼šæ–‡ä»¶åæŒ‰åŸå+æ—¶é—´æˆ³ï¼Œä¿ç•™æ‰©å±•åï¼›è‹¥æ— æ‰©å±•ååˆ™æ ¹æ® MIME çŒœæµ‹ã€‚"""
    if not msg.is_multipart():
        return

    import mimetypes
    import unicodedata
    from email.header import decode_header

    def _decode_filename(raw: str) -> str:
        """å°†å¯èƒ½è¢«æ‹†åˆ†ç¼–ç çš„æ–‡ä»¶åå„æ®µè§£ç å¹¶æ‹¼æ¥ï¼›è§„èŒƒåŒ–å…¨è§’ç‚¹ç­‰ã€‚"""
        parts = decode_header(raw)
        s = ""
        for p, enc in parts:
            if isinstance(p, bytes):
                s += p.decode(enc or "utf-8", errors="ignore")
            else:
                s += p
        s = unicodedata.normalize("NFC", s).replace("ï¼", ".").strip().strip(".")
        return s

    def _sanitize(name: str) -> str:
        """æ¸…ç†ä¸åˆæ³•æ–‡ä»¶åå­—ç¬¦ã€‚"""
        invalid = '<>:"/\\|?*'
        name = "".join((c if c not in invalid else "_") for c in name)
        # é¿å…éšè—åæˆ–ç©ºå
        name = name.strip().strip(".")
        return name or "attachment"

    def _guess_ext(content_type: str) -> str:
        """æ ¹æ® MIME çŒœæµ‹æ‰©å±•åï¼Œå†…ç½®å¸¸è§å…œåº•ã€‚"""
        overrides = {
            "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet": ".xlsx",
            "application/vnd.ms-excel": ".xls",
            "text/csv": ".csv",
            "application/zip": ".zip",
            "application/pdf": ".pdf",
        }
        return overrides.get(content_type) or (mimetypes.guess_extension(content_type) or "")

    def _ensure_unique(path: str) -> str:
        """å¦‚é‡ååˆ™åœ¨åŸºåæœ«å°¾è¿½åŠ (_2/_3...)é¿å…è¦†ç›–ã€‚"""
        if not os.path.exists(path):
            return path
        base, ext = os.path.splitext(path)
        i = 2
        while True:
            candidate = f"{base}_{i}{ext}"
            if not os.path.exists(candidate):
                return candidate
            i += 1

    for part in msg.walk():
        # è·³è¿‡å®¹å™¨éƒ¨ä»¶ï¼Œä»…å¤„ç†çœŸæ­£å†…å®¹/é™„ä»¶
        if part.get_content_maintype() == "multipart":
            continue

        content_disposition = str(part.get("Content-Disposition") or "")
        raw_name = part.get_filename()  # Python ä¼šå¤„ç† RFC2231 çš„ filename* æƒ…å†µ

        # æ—¢ä¸æ˜¯é™„ä»¶ä¹Ÿæ²¡æœ‰æ–‡ä»¶åçš„ï¼Œè·³è¿‡
        if "attachment" not in content_disposition and not raw_name:
            continue

        # 1) è§£ææ–‡ä»¶å
        if raw_name:
            filename = _decode_filename(raw_name)
        else:
            # æ²¡æœ‰æ–‡ä»¶åï¼Œç”¨ç±»å‹ç”Ÿæˆå ä½å
            filename = f"attachment{_guess_ext(part.get_content_type())}"

        # 2) æ‹†åˆ†æ‰©å±•åï¼›è‹¥ç¼ºå¤±åˆ™æ ¹æ® MIME çŒœæµ‹
        base_name, ext = os.path.splitext(filename)
        if not ext:
            ext = _guess_ext(part.get_content_type())

        # 3) è¿½åŠ æ—¶é—´æˆ³å¹¶æ¸…ç†æ–‡ä»¶å
        ts = time.strftime("%Y%m%d_%H%M%S")
        safe_base = _sanitize(base_name)
        safe_name = f"{safe_base}_{ts}{ext}"
        file_path = os.path.join(download_folder, safe_name)
        file_path = _ensure_unique(file_path)

        # 4) å†™å…¥ç£ç›˜
        file_data = part.get_payload(decode=True)
        if not file_data:
            continue
        with open(file_path, "wb") as f:
            f.write(file_data)

        print(f"ğŸ“¥ é™„ä»¶å·²ä¸‹è½½: {file_path}")


# ================================
# ğŸ§  è§£æ HTML è¡¨æ ¼å¹¶å¯¼å‡º Excel
# ================================
def parse_html_table(html_content: str) -> list[list[str]]:
    """
    è§£æ HTML è¡¨æ ¼ä¸ºäºŒç»´åˆ—è¡¨ï¼š
    1) ä¼˜å…ˆä½¿ç”¨ pandas.read_html
    2) å¤±è´¥åˆ™å›é€€åˆ° BeautifulSoupï¼Œå¹¶åœ¨å• <td> æ—¶æŒ‰ <br>/<p> æ‹†åˆ—
    è¿”å›ï¼š[[header...], [row1...], [row2...], ...]ï¼ˆå…¨ä¸ºå­—ç¬¦ä¸²ï¼‰
    """
    print("ğŸ”§ æ­£åœ¨è§£æ HTML è¡¨æ ¼...")

    # ---------- â‘  pandas ä¼˜å…ˆ ----------
    try:
        tables = pd.read_html(html_content)
    except Exception:
        tables = []

    if tables:
        def _score(df): return (df.shape[1], df.shape[0])
        df = max(tables, key=_score).copy()

        def _looks_numeric(s: str) -> bool:
            # çº¯æ•°å­—/æ•°å­—æ ¼å¼ï¼ˆå«é€—å·å°æ•°ç‚¹ï¼‰è®¤ä¸ºâ€œæ•°å­—æ ·â€
            return bool(re.fullmatch(r"[0-9\s,.\-]+", (s or "").strip()))

        if isinstance(df.columns, pd.RangeIndex):
            first_row = df.iloc[0].astype(str).str.strip().tolist()

            # åˆ¤å®šé¦–è¡Œæ˜¯å¦åƒè¡¨å¤´ï¼šå‡ºç°ä¸­æ–‡/å­—æ¯çš„æ¯”ä¾‹ã€æˆ–åŒ…å«å¸¸è§è¡¨å¤´å…³é”®è¯
            non_numeric_ratio = sum(1 for v in first_row if v and not _looks_numeric(v)) / max(len(first_row), 1)
            header_keywords = ("ä»“åº“", "ç¼–ç ", "åç§°", "è§„æ ¼", "å‹å·", "æ•°é‡", "é‡‘é¢", "å•ä»·", "åˆè®¡", "å¤‡æ³¨")

            if (non_numeric_ratio >= 0.4) or any(k in "".join(first_row) for k in header_keywords):
                header = first_row
                df = df.iloc[1:].reset_index(drop=True)
            else:
                header = [str(c) for c in df.columns]
        else:
            if isinstance(df.columns, pd.MultiIndex):
                header = [
                    " ".join([str(x) for x in tup if str(x) != "nan"]).strip()
                    for tup in df.columns.tolist()
                ]
            else:
                header = [str(c) for c in df.columns]

        rows = (
            df.fillna("")
              .astype(str)
              .applymap(lambda x: x.strip())
              .values
              .tolist()
        )
        data = [header] + rows

        # å…œåº•ï¼šè‹¥è¡¨å¤´æ˜¯ '0..N-1' è¿™ç§ç´¢å¼•æ ·å¼ï¼Œåˆ æ‰å¹¶ç”¨ä¸‹ä¸€è¡Œå½“è¡¨å¤´
        if data and all(h.isdigit() for h in data[0]) and \
           [int(x) for x in data[0]] == list(range(len(data[0]))) and len(data) >= 2:
            data = [data[1]] + data[2:]

        print(f"âœ… pandas è§£ææˆåŠŸï¼š{len(data)} è¡Œï¼Œ{len(data[0]) if data else 0} åˆ—ã€‚")
        return data

    # ---------- â‘¡ BeautifulSoup å›é€€ ----------
    def _parse_html_with_bs(html: str) -> list[list[str]]:
        soup = BeautifulSoup(html, "html.parser")
        tables = soup.find_all("table")
        if not tables:
            print("æœªæ‰¾åˆ°ä»»ä½• <table>ã€‚")
            return []

        best_data, best_cols = [], 0

        for table in tables:
            rows_data = []
            for tr in table.find_all("tr"):
                cells = tr.find_all(["td", "th"])
                if not cells:
                    continue

                if len(cells) == 1:
                    # æŠŠå•å…ƒæ ¼é‡Œçš„ <br>/<p> å½“ä½œâ€œåˆ—åˆ†éš”â€
                    text = cells[0].get_text(separator="|", strip=True)
                    cols = [seg.strip() for seg in text.split("|") if seg.strip() != ""]
                else:
                    cols = [td.get_text(" ", strip=True) for td in cells]

                rows_data.append(cols)

            if not rows_data:
                continue

            n_cols = max((len(r) for r in rows_data), default=0)
            if n_cols > best_cols or (n_cols == best_cols and len(rows_data) > len(best_data)):
                normalized, header = [], None
                for row in rows_data:
                    if not row:
                        continue
                    if len(row) < n_cols:
                        row = row + [""] * (n_cols - len(row))
                    elif len(row) > n_cols:
                        row = row[:n_cols]
                    if header is None:
                        header = row
                        normalized.append(header)
                    else:
                        if row == header:
                            continue
                        normalized.append(row)
                best_data, best_cols = normalized, n_cols

        # åŒæ ·çš„å…œåº•ï¼šå»æ‰ '0..N-1' ä¼ªè¡¨å¤´
        if best_data and all(h.isdigit() for h in best_data[0]) and \
           [int(x) for x in best_data[0]] == list(range(len(best_data[0]))) and len(best_data) >= 2:
            best_data = [best_data[1]] + best_data[2:]

        if best_data:
            print(f"âœ… BeautifulSoup å›é€€è§£ææˆåŠŸï¼š{len(best_data)} è¡Œï¼Œ{best_cols} åˆ—ã€‚")
        else:
            print("æœªèƒ½è§£æå‡ºè¡¨æ ¼æ•°æ®ã€‚")
        return best_data

    return _parse_html_with_bs(html_content)



def save_to_excel(data: list[list[str]], save_dir: str, file_prefix="å­˜é‡æŸ¥è¯¢") -> None:
    if not data:
        print("â„¹ï¸ æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®ã€‚")
        return

    # å»é‡ï¼ˆä¿åºï¼‰
    seen = set()
    unique_data = []
    for row in data:
        tup = tuple(row)
        if tup not in seen:
            seen.add(tup)
            unique_data.append(row)

    df = pd.DataFrame(unique_data)

    # æ–‡ä»¶ååŠ æ—¶é—´æˆ³
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    file_name = f"{file_prefix}_{timestamp}.xlsx"
    full_path = os.path.join(save_dir, file_name)

    print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜ Excelï¼š{full_path}")
    # ä¸å†™ headerï¼ˆåŸé€»è¾‘ï¼‰
    df.to_excel(full_path, index=False, header=False)

    # openpyxl å†ç»†åŒ–æ ¼å¼
    wb = openpyxl.load_workbook(full_path)
    ws = wb.active
    ws.title = "ç¬¬ä¸€é¡µ"

    # ç¤ºä¾‹ï¼šå°è¯•å¯¹ç¬¬5åˆ—ã€ç¬¬6åˆ—åº”ç”¨åƒåˆ†ä½ & å³å¯¹é½ï¼ˆä»…å½“å¤šæ•°å¯è¢«è¯†åˆ«ä¸ºæ•°å€¼ï¼‰
    decimal_columns = [4, 5]  # 0-based ç´¢å¼•ï¼Œå¯¹åº”ç¬¬5/6åˆ—
    max_row = ws.max_row
    for col in decimal_columns:
        # ç»Ÿè®¡æ•°å€¼æ¯”ä¾‹
        numeric_count = 0
        for r in range(2, max_row + 1):
            val = ws.cell(row=r, column=col + 1).value
            try:
                float(str(val).replace(",", ""))  # å°è¯•å¯è½¬æ•°
                numeric_count += 1
            except Exception:
                pass
        # è¶…è¿‡ä¸€åŠå¯è§†ä¸ºæ•°å€¼ â†’ åº”ç”¨æ ¼å¼
        if numeric_count >= (max_row - 1) / 2:
            for r in range(2, max_row + 1):
                cell = ws.cell(row=r, column=col + 1)
                try:
                    v = float(str(cell.value).replace(",", ""))
                    cell.value = v
                    cell.number_format = '#,##0.00'
                    cell.alignment = Alignment(horizontal='right')
                except Exception:
                    # æ— æ³•è½¬æ•°å€¼å°±è·³è¿‡
                    pass

    wb.save(full_path)
    print("âœ… Excel ä¿å­˜å®Œæˆã€‚")

def _write_meta(meta: dict, path: str) -> None:
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(meta, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“ å…ƒæ•°æ®å·²å†™å…¥: {path}")
    except Exception as e:
        print(f"âš ï¸ å…ƒæ•°æ®å†™å…¥å¤±è´¥: {e}")

# ================================
# ğŸš€ ä¸»ç¨‹åº
# ================================
if __name__ == '__main__':
    print("ç¨‹åºå¯åŠ¨")
    html_content = fetch_html_from_emails(email_server, email_user, email_password, excel_save_path)

    if html_content:
        preview = html_content[:400].replace("\n", " ")
        print(f"HTML é¢„è§ˆ: {preview} ...")

        table_data = parse_html_table(html_content)
        if table_data:
            save_to_excel(table_data, excel_save_path, file_prefix="å­˜é‡æŸ¥è¯¢")
        else:
            print("è¡¨æ ¼ä¸ºç©ºï¼Œæœªå¯¼å‡º Excelã€‚")
    else:
        print("æœªè·å–åˆ° HTMLï¼Œç¨‹åºç»“æŸã€‚")
