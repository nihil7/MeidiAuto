import os
import time
import random
import cloudscraper
from datetime import datetime
from dotenv import load_dotenv

# === åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆä»…é™æœ¬åœ°ï¼‰===
if not os.getenv("GITHUB_ACTIONS", "").lower() == "true":
    load_dotenv()

# === è¯·æ±‚å¤´ä¿¡æ¯ ===
headers = {
    'User-Agent': 'Mozilla/5.0',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'zh-CN,zh;q=0.9',
    'Connection': 'keep-alive'
}

# === Cloudflare å…¼å®¹è¯·æ±‚å¯¹è±¡ ===
scraper = cloudscraper.create_scraper()

# === ç»Ÿä¸€é…ç½®æ‰€æœ‰ç½‘ç«™ ===
SITES = {
    "PTTIME": {
        "url": "https://www.pttime.org/attendance.php?type=sign&uid={uid}",
        "accounts": {
            "A": {"uid": "2785"},
            "B": {"uid": "20801"}
        }
    },
    "XXXFORUM": {
    "url": "https://1ptba.com/attendance.php",  # æ²¡æœ‰ {uid}
    "accounts": {
        "X1": {},
        "X2": {}
    }
}
}

# === è¯»å–æŸè´¦å·çš„ Cookie ===
def build_cookie(site, account):
    prefix = f"{site}_{account}".upper()
    return {
        'logged_in': os.getenv(f'{prefix}_LOGGED_IN'),
        'cf_clearance': os.getenv(f'{prefix}_CF_CLEARANCE'),
        'c_secure_uid': os.getenv(f'{prefix}_C_SECURE_UID'),
        'c_secure_tracker_ssl': os.getenv(f'{prefix}_C_SECURE_TRACKER_SSL'),
        'c_secure_ssl': os.getenv(f'{prefix}_C_SECURE_SSL'),
        'c_secure_pass': os.getenv(f'{prefix}_C_SECURE_PASS'),
        'c_secure_login': os.getenv(f'{prefix}_C_SECURE_LOGIN'),
        'c_lang_folder': os.getenv(f'{prefix}_C_LANG_FOLDER'),
    }

# === Cookie æ£€æŸ¥ ===
def is_cookie_valid(cookie_dict):
    return all(cookie_dict.values())

# === æ‰“å° Cookie ç®€è¦ ===
def print_cookie_info(name, cookie_dict):
    print(f"ğŸª {name} cookies:")
    for k, v in cookie_dict.items():
        print(f"  {k} = {v if v else 'âŒ ç¼ºå¤±'}")

# === æ‰§è¡Œç­¾åˆ° ===
def check_in(full_url, cookies, site, account):
    print(f"ğŸš€ æ­£åœ¨ç­¾åˆ° [{site} - {account}]: {full_url}")
    try:
        response = scraper.get(full_url, cookies=cookies, headers=headers, timeout=10)
        print(f"âœ… çŠ¶æ€ç : {response.status_code}")
        print(f"ğŸ“„ å†…å®¹ï¼ˆå‰200å­—ï¼‰: {response.text[:200]}...")
        if response.status_code == 200:
            now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            print(f"ğŸ‰ æˆåŠŸç­¾åˆ°ï¼š{site} - {account} @ {now}")
        else:
            print(f"âŒ ç­¾åˆ°å¤±è´¥ï¼š{site} - {account}")
    except Exception as e:
        print(f"ğŸš¨ è¯·æ±‚å¼‚å¸¸ï¼š{site} - {account} - {str(e)}")

# === ä¸»å‡½æ•° ===
def main():
    for site, site_info in SITES.items():
        url_template = site_info["url"]
        for account, info in site_info["accounts"].items():
            cookie = build_cookie(site, account)
            print_cookie_info(f"{site}-{account}", cookie)

            if not is_cookie_valid(cookie):
                print(f"âš ï¸ è·³è¿‡ï¼š{site} - {account}ï¼ŒCookie ä¿¡æ¯ä¸å®Œæ•´")
                continue

            full_url = url_template.format(**info) if '{' in url_template else url_template
            check_in(full_url, cookie, site, account)

            delay = random.uniform(0, 5)
            print(f"â³ ç­‰å¾… {delay:.2f} ç§’...\n")
            time.sleep(delay)

if __name__ == "__main__":
    main()
